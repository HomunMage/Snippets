---
layout: board
title:  "AI架構與原理"
date:   2023-04-01 10:00:00 +0800
categories: [Theory]
---

BERT是encoder，會對一段文字看context(上下文)去做整體的理解；transformer則是decoder，用來預測下一個段落的生成。

昨天的m觀點提到bard和gpt方向上的差異：bard是google用來理解文章輔助搜尋的AI，gpt則是OpenAI專注在生成可用內容的AI，把讓擅長理解的bard拿來聊天本來就會有表現不佳的狀況。這個說法白話多了。 

gpt和bert的原理
<iframe width="450" height="255" src="https://www.youtube.com/embed/S3xgoFFwlpM" title="YouTube video player" frameborder="0" ></iframe>

解說transformer原理
<iframe width="450" height="255" src="https://www.youtube.com/embed/08J22Zs0F6Q" title="YouTube video player" frameborder="0" ></iframe>

解釋得很清楚是語言架構的結果 並不是媒體所渲染的具有心智
https://www.youtube.com/watch?v=U4CDhaGejKs
<iframe width="450" height="255" src="https://www.youtube.com/embed/U4CDhaGejKs" title="YouTube video player" frameborder="0" ></iframe>